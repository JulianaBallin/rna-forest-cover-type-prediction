{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVPf2qACAJBU"
      },
      "source": [
        "# Redes Neurais Artificiais 2025.2\n",
        "\n",
        "- **Disciplina**: Redes Neurais Artificiais 2025.2\n",
        "- **Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "- **Github**: http://github.com/elloa  \n",
        "        \n",
        "\n",
        "Levando em conta a base de dados **_Forest Cover Type_**, esta parte do Projeto Prático diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
        "\n",
        "## Busca em Grade\n",
        "\n",
        "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
        "\n",
        "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
        "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
        "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
        "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
        "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
        "\n",
        "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
        "\n",
        "## Efetuando a Busca em Grade sobre Hiperparâmetros das Top-6 RNAs\n",
        "\n",
        "Considerando a etapa anterior do projeto prático, foram identificadas pelo menos 6 melhores Redes Neurais para o problema da classificação multi-classe da cobertura florestal no conjunto de dados selecionado. Algumas destas redes possuem atributos categóricos como variáveis preditoras, enquanto outras possuem apenas os atributos numéricos como preditores.\n",
        "\n",
        "A primeira etapa desta segunda parte do projeto consiste em trazer para este notebook estas seis arquiteturas, ressaltando:\n",
        "\n",
        "1. Número de neurônios ocultos por camada  \n",
        "2. Função de Ativação  \n",
        "3. Utilização ou não de atributos categóricos   \n",
        "4. Desempenho médio +- desvio padrão nos testes anteriores  \n",
        "5. Número de repetições que a equipe conseguiu realizar para verificar os resultados  \n",
        "\n",
        "Elabore uma busca em grade sobre estas arquiteturas que contemple variações nos hiperparâmetros a seguir, conforme documentação de [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
        "\n",
        "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
        "B. Batch Size  \n",
        "C. Learning Rate Init  \n",
        "D. Paciência (n_iter_no_change)  \n",
        "E. Épocas  \n",
        "\n",
        "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYN5DbptAJBW"
      },
      "source": [
        "## Validação Cruzada k-fold\n",
        "\n",
        "Na elaboração da busca em grid, vamos avaliar os modelos propostos segundo uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
        "\n",
        "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
        "\n",
        "Considerando a métrica de desempenho F1-Score, considere a validação cruzada 5-fold para aferir os resultados da busca em grande anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIwpixvWH8iN"
      },
      "outputs": [],
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn torch torchvision torchaudio kagglehub ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gjrfZklAJBY",
        "outputId": "16a9fff1-b396-4484-a151-1dcf700ff3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'forest-cover-type-dataset' dataset.\n",
            "Dataset baixado em: /kaggle/input/forest-cover-type-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Baixar o dataset do Kaggle\n",
        "path = kagglehub.dataset_download(\"uciml/forest-cover-type-dataset\")\n",
        "print(\"Dataset baixado em:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Bojm2PAJBZ",
        "outputId": "13582ac2-2674-49ab-ca92-43e9a4c40297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some files in /kaggle/input/forest-cover-type-dataset:\n",
            "['/kaggle/input/forest-cover-type-dataset/covtype.csv']\n",
            "Using CSV_PATH = /kaggle/input/forest-cover-type-dataset/covtype.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell A — locate dataset in Colab cache\n",
        "import os, pprint, glob\n",
        "candidates = glob.glob('/kaggle/input/forest-cover-type-dataset/**', recursive=True)\n",
        "files = [p for p in candidates if os.path.isfile(p)]\n",
        "print(\"Some files in /kaggle/input/forest-cover-type-dataset:\")\n",
        "pprint.pprint(files[:20])\n",
        "# Common CSV path:\n",
        "CSV_PATH = '/kaggle/input/forest-cover-type-dataset/covtype.csv'\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    # fallback: find any covtype*.csv\n",
        "    import glob\n",
        "    found = glob.glob('/kaggle/input/**/covtype*.csv', recursive=True)\n",
        "    if found:\n",
        "        CSV_PATH = found[0]\n",
        "    else:\n",
        "        raise FileNotFoundError(\"covtype.csv not found in /kaggle/input; check files list above.\")\n",
        "print(\"Using CSV_PATH =\", CSV_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "n0sKFvJQAJBa",
        "outputId": "63e6866c-ee57-4ef3-bc50-732dcee4e7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded df shape: (581012, 55)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ba784b50-e462-46ce-9399-bd121aa13f70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba784b50-e462-46ce-9399-bd121aa13f70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba784b50-e462-46ce-9399-bd121aa13f70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba784b50-e462-46ce-9399-bd121aa13f70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ceebe0af-f8f5-44a8-a640-afd0ff336be2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ceebe0af-f8f5-44a8-a640-afd0ff336be2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ceebe0af-f8f5-44a8-a640-afd0ff336be2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
              "0                                6279  ...            0            0   \n",
              "1                                6225  ...            0            0   \n",
              "2                                6121  ...            0            0   \n",
              "3                                6211  ...            0            0   \n",
              "4                                6172  ...            0            0   \n",
              "\n",
              "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0            0            0           5  \n",
              "1            0            0           5  \n",
              "2            0            0           2  \n",
              "3            0            0           2  \n",
              "4            0            0           5  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns (first 20): ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6']\n"
          ]
        }
      ],
      "source": [
        "# Cell B — load CSV and quick inspect\n",
        "import pandas as pd\n",
        "CSV_PATH = '/kaggle/input/forest-cover-type-dataset/covtype.csv'  # adjust if needed\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Loaded df shape:\", df.shape)\n",
        "display(df.head())\n",
        "print(\"Columns (first 20):\", df.columns.tolist()[:20])\n",
        "# configure sample size: None to use all data (careful!), or integer to subsample stratified\n",
        "MAX_SAMPLES = None   # safe default for Colab; set to None to use full dataset if you have time/ram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e9hB6ixAJBb",
        "outputId": "a417e4f1-eadc-4ce3-9283-1e26755c3d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target column: Cover_Type\n",
            "Original dataset size: (581012, 54)\n",
            "Using sample shape: (581012, 54) n_classes: 7\n"
          ]
        }
      ],
      "source": [
        "# Cell C — prepare X, y and optional stratified sampling\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "target_col = 'Cover_Type' if 'Cover_Type' in df.columns else df.columns[-1]\n",
        "print(\"Target column:\", target_col)\n",
        "X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
        "y = df[target_col].values.astype(np.int64)\n",
        "# convert labels from 1..7 to 0..6 if needed\n",
        "if y.min() == 1:\n",
        "    y = y - 1\n",
        "\n",
        "print(\"Original dataset size:\", X.shape)\n",
        "\n",
        "if MAX_SAMPLES is not None and X.shape[0] > MAX_SAMPLES:\n",
        "    print(f\"Stratified sampling to {MAX_SAMPLES} samples...\")\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=MAX_SAMPLES, random_state=42)\n",
        "    for _, idx in sss.split(X, y):\n",
        "        X_sample = X[idx]\n",
        "        y_sample = y[idx]\n",
        "else:\n",
        "    X_sample, y_sample = X, y\n",
        "\n",
        "print(\"Using sample shape:\", X_sample.shape, \"n_classes:\", len(np.unique(y_sample)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM9goNh9Hxee",
        "outputId": "68397541-1c3e-49ea-efd1-35d9aea20790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell D — PyTorch helpers\n",
        "import torch, gc\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, max(hidden_dim//2, 8)),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(max(hidden_dim//2, 8), n_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(Xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb = Xb.to(device)\n",
        "            logits = model(Xb)\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            ps.append(preds)\n",
        "            ys.append(yb.numpy())\n",
        "    y_true = np.concatenate(ys)\n",
        "    y_pred = np.concatenate(ps)\n",
        "    return float(f1_score(y_true, y_pred, average='weighted')), y_true, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kO9QDi7YKe-",
        "outputId": "07c080e0-774a-4140-8a9b-cb4a00a830f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim: 54 n_classes: 7\n",
            "Testing cfg: {'hidden_dim': 128, 'lr': 0.001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.8342 (time 234.5s)\n",
            "Testing cfg: {'hidden_dim': 128, 'lr': 0.0001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.7591 (time 233.1s)\n",
            "Testing cfg: {'hidden_dim': 256, 'lr': 0.001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.8650 (time 233.8s)\n",
            "Testing cfg: {'hidden_dim': 256, 'lr': 0.0001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.7837 (time 233.1s)\n",
            "\n",
            "Best config: {'hidden_dim': 256, 'lr': 0.001, 'batch_size': 256, 'epochs': 8} best_cv_f1 = 0.8649654852949569\n",
            "Saved grid search summary to /content/grid_search_results.json\n"
          ]
        }
      ],
      "source": [
        "# Cell E — grid search manual (small grid); adjust param_grid for more experiments\n",
        "import time, itertools, json\n",
        "from copy import deepcopy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import gc\n",
        "\n",
        "n_classes = len(np.unique(y_sample))\n",
        "input_dim = X_sample.shape[1]\n",
        "print(\"input_dim:\", input_dim, \"n_classes:\", n_classes)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_dim': [128, 256],\n",
        "    'lr': [1e-3, 1e-4],\n",
        "    'batch_size': [256],\n",
        "    'epochs': [8]\n",
        "}\n",
        "\n",
        "def iter_grid(grid):\n",
        "    keys = list(grid.keys())\n",
        "    for vals in itertools.product(*(grid[k] for k in keys)):\n",
        "        yield dict(zip(keys, vals))\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_cfg, best_score = None, -1.0\n",
        "results = []\n",
        "\n",
        "for cfg in iter_grid(param_grid):\n",
        "    fold_scores = []\n",
        "    t0 = time.time()\n",
        "    print(\"Testing cfg:\", cfg)\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_sample, y_sample), 1):\n",
        "        # fit scaler on train fold\n",
        "        scaler = StandardScaler()\n",
        "        X_train_fold = scaler.fit_transform(X_sample[train_idx])\n",
        "        X_val_fold = scaler.transform(X_sample[val_idx])\n",
        "        y_train_fold = y_sample[train_idx]\n",
        "        y_val_fold = y_sample[val_idx]\n",
        "\n",
        "        train_ds = NumpyDataset(X_train_fold, y_train_fold)\n",
        "        val_ds = NumpyDataset(X_val_fold, y_val_fold)\n",
        "        train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=cfg['batch_size'], shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=input_dim, hidden_dim=cfg['hidden_dim'], n_classes=n_classes).to(device)\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for ep in range(cfg['epochs']):\n",
        "            _ = train_one_epoch(model, train_loader, opt, criterion)\n",
        "\n",
        "        f1_val, _, _ = eval_model(model, val_loader)\n",
        "        fold_scores.append(f1_val)\n",
        "\n",
        "        # cleanup\n",
        "        del model, opt, criterion, train_loader, val_loader, train_ds, val_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    mean_f1 = float(np.mean(fold_scores))\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"  Mean F1 5-fold = {mean_f1:.4f} (time {elapsed:.1f}s)\")\n",
        "    results.append((cfg, mean_f1))\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_cfg = deepcopy(cfg)\n",
        "\n",
        "print(\"\\nBest config:\", best_cfg, \"best_cv_f1 =\", best_score)\n",
        "# save results\n",
        "with open('/content/grid_search_results.json', 'w') as f:\n",
        "    json.dump({'best': best_cfg, 'best_score': best_score, 'results': [[r[0], r[1]] for r in results]}, f, indent=2)\n",
        "print(\"Saved grid search summary to /content/grid_search_results.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA7c50uTYQPf",
        "outputId": "d1706486-fa15-48b6-87b9-3b68d668719d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training final with: {'hidden_dim': 256, 'lr': 0.001, 'batch_size': 256, 'epochs': 8}\n",
            "Epoch 1/8 - loss: 0.5936\n",
            "Epoch 2/8 - loss: 0.4880\n",
            "Epoch 3/8 - loss: 0.4481\n",
            "Epoch 4/8 - loss: 0.4226\n",
            "Epoch 5/8 - loss: 0.4046\n",
            "Epoch 6/8 - loss: 0.3909\n",
            "Epoch 7/8 - loss: 0.3794\n",
            "Epoch 8/8 - loss: 0.3691\n",
            "Saved model to /content/cover_mlp_best.pth\n",
            "Saved scaler to /content/cover_scaler.pkl\n",
            "Saved training summary to /content/cover_training_summary.json\n"
          ]
        }
      ],
      "source": [
        "# Cell F — train final on X_sample with scaler + save model & scaler\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "best = best_cfg\n",
        "print(\"Training final with:\", best)\n",
        "\n",
        "scaler_final = StandardScaler()\n",
        "X_scaled = scaler_final.fit_transform(X_sample)\n",
        "y_final = y_sample\n",
        "\n",
        "final_ds = NumpyDataset(X_scaled, y_final)\n",
        "final_loader = DataLoader(final_ds, batch_size=best['batch_size'], shuffle=True)\n",
        "\n",
        "model_final = MLP(input_dim=input_dim, hidden_dim=best['hidden_dim'], n_classes=n_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model_final.parameters(), lr=best['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(best['epochs']):\n",
        "    loss = train_one_epoch(model_final, final_loader, optimizer, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{best['epochs']} - loss: {loss:.4f}\")\n",
        "\n",
        "MODEL_PATH = '/content/cover_mlp_best.pth'\n",
        "SCALER_PATH = '/content/cover_scaler.pkl'\n",
        "torch.save(model_final.state_dict(), MODEL_PATH)\n",
        "joblib.dump(scaler_final, SCALER_PATH)\n",
        "print(\"Saved model to\", MODEL_PATH)\n",
        "print(\"Saved scaler to\", SCALER_PATH)\n",
        "\n",
        "# save summary\n",
        "summary = {\n",
        "    'n_total_available': int(X.shape[0]),\n",
        "    'n_used_sample': int(X_sample.shape[0]),\n",
        "    'best_cfg': best,\n",
        "    'best_cv_f1': best_score,\n",
        "    'model_path': MODEL_PATH,\n",
        "    'scaler_path': SCALER_PATH\n",
        "}\n",
        "import json\n",
        "with open('/content/cover_training_summary.json', 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "print(\"Saved training summary to /content/cover_training_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axxjZKd_AJBb"
      },
      "source": [
        "## Identificando a mellhor solução\n",
        "\n",
        "Como resultado da busca em grande com validação cruzada 5-fold, identifique o modelo otimizado com melhor desempenho para o problema. Apresente claramente este modelo, seus parâmetros, hiperparâmetros otimizados e resultados para cada um dos folds avaliados. Esta é a melhor solução identificada em decorrência deste projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56vl-eZyAJBc",
        "outputId": "8f0a42b1-9e27-4290-cfc9-fe252a069ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados: X=(60000, 54), y=(60000,), classes=8, device=cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, json, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try: torch.set_float32_matmul_precision(\"high\")\n",
        "except: pass\n",
        "\n",
        "# Descobre X/y vindos do notebook; senão usa covertype da sklearn\n",
        "def _pick_xy():\n",
        "    for Xn, yn in [(\"Xcv\",\"ycv\"), (\"X_use\",\"y_use\"), (\"X\",\"y\")]:\n",
        "        if Xn in globals() and yn in globals():\n",
        "            X_, y_ = globals()[Xn], globals()[yn]\n",
        "            return np.asarray(X_, dtype=np.float32), np.asarray(y_, dtype=int)\n",
        "    # fallback: covertype\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_ = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_ = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "    # amostra pra caber no Colab se precisar\n",
        "    if X_.shape[0] > 60000:\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_, _, y_, _ = train_test_split(X_, y_, train_size=60000, stratify=y_, random_state=42)\n",
        "    return X_.astype(np.float32), y_\n",
        "\n",
        "X_all, y_all = _pick_xy()\n",
        "n_features = X_all.shape[1]; n_classes = int(np.max(y_all))+1\n",
        "print(f\"Dados: X={X_all.shape}, y={y_all.shape}, classes={n_classes}, device={DEVICE}\")\n",
        "\n",
        "# Modelo MLP simples\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers, d = [], in_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(d, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            d = h\n",
        "        layers += [nn.Linear(d, out_dim)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def train_one_fold(X_tr, y_tr, X_va, y_va, config, max_epochs=200, patience=15, bs=2048):\n",
        "    # scaler por fold\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    Xt = scaler.transform(X_tr).astype(np.float32)\n",
        "    Xv = scaler.transform(X_va).astype(np.float32)\n",
        "\n",
        "    tl = DataLoader(TensorDataset(torch.from_numpy(Xt), torch.from_numpy(y_tr)), batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    vl = DataLoader(TensorDataset(torch.from_numpy(Xv), torch.from_numpy(y_va)), batch_size=bs, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = MLP(n_features, config[\"hidden\"], n_classes, dropout=config.get(\"dropout\",0.2)).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config.get(\"wd\",1e-4))\n",
        "    scaler_amp = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_f1, best_state, noimp = -1.0, None, 0\n",
        "    for ep in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        for xb, yb in tl:\n",
        "            xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE.type==\"cuda\")):\n",
        "                loss = crit(model(xb), yb)\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "\n",
        "        # valida\n",
        "        model.eval(); preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in vl:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE.type==\"cuda\")):\n",
        "                    p = model(xb).argmax(1).cpu()\n",
        "                preds.append(p); gts.append(yb)\n",
        "        yv = torch.cat(gts).numpy(); pv = torch.cat(preds).numpy()\n",
        "        f1 = f1_score(yv, pv, average=\"macro\")\n",
        "\n",
        "        if f1 > best_f1 + 1e-4:\n",
        "            best_f1, noimp = f1, 0\n",
        "            best_state = {k: v.cpu() for k,v in model.state_dict().items()}\n",
        "        else:\n",
        "            noimp += 1\n",
        "            if noimp >= patience: break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_f1, model.cpu(), scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_E9SBFNFAJBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83072ec0-b41c-4fd2-f2b5-f503b65aa3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMP: usando torch.amp ✓\n",
            "mlp_128_lr1e-3 | fold 1/5  F1-macro=0.6540 | elapsed=184.4s\n",
            "mlp_128_lr1e-3 | fold 2/5  F1-macro=0.6041 | elapsed=48.8s\n",
            "mlp_128_lr1e-3 | fold 3/5  F1-macro=0.6629 | elapsed=81.4s\n",
            "mlp_128_lr1e-3 | fold 4/5  F1-macro=0.6569 | elapsed=83.8s\n",
            "mlp_128_lr1e-3 | fold 5/5  F1-macro=0.6495 | elapsed=88.9s\n",
            "→ mlp_128_lr1e-3 total=487.4s\n",
            "\n",
            "mlp_128_lr5e-4 | fold 1/5  F1-macro=0.6145 | elapsed=90.1s\n",
            "mlp_128_lr5e-4 | fold 2/5  F1-macro=0.6065 | elapsed=111.2s\n",
            "mlp_128_lr5e-4 | fold 3/5  F1-macro=0.6316 | elapsed=150.7s\n",
            "mlp_128_lr5e-4 | fold 4/5  F1-macro=0.6138 | elapsed=154.4s\n",
            "mlp_128_lr5e-4 | fold 5/5  F1-macro=0.5922 | elapsed=140.8s\n",
            "→ mlp_128_lr5e-4 total=647.3s\n",
            "\n",
            "mlp_256_lr1e-3 | fold 1/5  F1-macro=0.7049 | elapsed=198.8s\n",
            "mlp_256_lr1e-3 | fold 2/5  F1-macro=0.6485 | elapsed=69.2s\n",
            "mlp_256_lr1e-3 | fold 3/5  F1-macro=0.6768 | elapsed=70.0s\n",
            "mlp_256_lr1e-3 | fold 4/5  F1-macro=0.6878 | elapsed=94.0s\n",
            "mlp_256_lr1e-3 | fold 5/5  F1-macro=0.6615 | elapsed=75.9s\n",
            "→ mlp_256_lr1e-3 total=507.9s\n",
            "\n",
            "mlp_256_lr5e-4 | fold 1/5  F1-macro=0.6455 | elapsed=101.7s\n",
            "mlp_256_lr5e-4 | fold 2/5  F1-macro=0.6354 | elapsed=102.9s\n",
            "mlp_256_lr5e-4 | fold 3/5  F1-macro=0.6255 | elapsed=81.9s\n",
            "mlp_256_lr5e-4 | fold 4/5  F1-macro=0.6090 | elapsed=69.8s\n",
            "mlp_256_lr5e-4 | fold 5/5  F1-macro=0.6411 | elapsed=157.8s\n",
            "→ mlp_256_lr5e-4 total=514.1s\n",
            "\n",
            "\n",
            ">>> MELHOR CONFIG: {'name': 'mlp_256_lr1e-3', 'hidden': [256], 'lr': 0.001} | F1-macro CV = 0.6759 ± 0.0197\n",
            "Resultados por fold (F1-macro): [0.7049 0.6485 0.6768 0.6878 0.6615]\n",
            "[OOF] fold 1: F1-macro=0.6995\n",
            "[OOF] fold 2: F1-macro=0.6616\n",
            "[OOF] fold 3: F1-macro=0.7021\n",
            "[OOF] fold 4: F1-macro=0.6886\n"
          ]
        },
        
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-1834973047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mfold_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_scalers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     f1, model, scaler = train_one_fold(X_all[tr], y_all[tr], X_all[va], y_all[va],\n\u001b[0m\u001b[1;32m    132\u001b[0m                                        best_config, max_epochs=120, patience=12, bs=2048)\n\u001b[1;32m    133\u001b[0m     \u001b[0mXv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-1834973047.py\u001b[0m in \u001b[0;36mtrain_one_fold\u001b[0;34m(X_tr, y_tr, X_va, y_va, config, max_epochs, patience, bs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time, json, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "from contextlib import nullcontext\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "USE_CUDA = (DEVICE.type == \"cuda\")\n",
        "\n",
        "try:\n",
        "    from torch import amp\n",
        "    def AMP():\n",
        "        return amp.autocast(\"cuda\", dtype=torch.float16) if USE_CUDA else nullcontext()\n",
        "    def make_scaler():\n",
        "        return amp.GradScaler(\"cuda\") if USE_CUDA else None\n",
        "    print(\"AMP: usando torch.amp ✓\")\n",
        "except Exception:\n",
        "    from torch.cuda.amp import autocast as legacy_autocast, GradScaler as LegacyGradScaler\n",
        "    def AMP():\n",
        "        return legacy_autocast(enabled=USE_CUDA, dtype=torch.float16)\n",
        "    def make_scaler():\n",
        "        return LegacyGradScaler(enabled=USE_CUDA)\n",
        "    print(\"AMP: usando torch.cuda.amp (legacy) ✓\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try: torch.set_float32_matmul_precision(\"high\")\n",
        "except: pass\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "assert \"X_all\" in globals() and \"y_all\" in globals(), \"Cadê X_all/y_all? Rode a célula G1 antes.\"\n",
        "assert \"n_features\" in globals() and \"n_classes\" in globals(), \"Cadê n_features/n_classes? Rode a célula G1 antes.\"\n",
        "assert \"MLP\" in globals(), \"Cadê a classe MLP? Ela é definida na G1.\"\n",
        "\n",
        "# função de treino\n",
        "def train_one_fold(X_tr, y_tr, X_va, y_va, config, max_epochs=120, patience=12, bs=2048):\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    Xt = scaler.transform(X_tr).astype(np.float32)\n",
        "    Xv = scaler.transform(X_va).astype(np.float32)\n",
        "\n",
        "    tl = DataLoader(TensorDataset(torch.from_numpy(Xt), torch.from_numpy(y_tr)), batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    vl = DataLoader(TensorDataset(torch.from_numpy(Xv), torch.from_numpy(y_va)), batch_size=bs, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = MLP(n_features, config[\"hidden\"], n_classes, dropout=config.get(\"dropout\", 0.2)).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config.get(\"wd\", 1e-4))\n",
        "    scaler_amp = make_scaler()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_f1, noimp, best_state = -1.0, 0, None\n",
        "    for ep in range(1, max_epochs + 1):\n",
        "        # treino\n",
        "        model.train()\n",
        "        for xb, yb in tl:\n",
        "            xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with AMP():\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "            if scaler_amp is not None:\n",
        "                scaler_amp.scale(loss).backward()\n",
        "                scaler_amp.step(opt)\n",
        "                scaler_amp.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "        # validação\n",
        "        model.eval(); preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in vl:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                with AMP():\n",
        "                    p = model(xb).argmax(1).cpu()\n",
        "                preds.append(p); gts.append(yb)\n",
        "        yv = torch.cat(gts).numpy(); pv = torch.cat(preds).numpy()\n",
        "        f1 = f1_score(yv, pv, average=\"macro\")\n",
        "\n",
        "        if f1 > best_f1 + 1e-4:\n",
        "            best_f1, noimp = f1, 0\n",
        "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            noimp += 1\n",
        "            if noimp >= patience:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_f1, model.cpu(), scaler\n",
        "\n",
        "# =====================================================================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid = [\n",
        "    {\"name\":\"mlp_128_lr1e-3\", \"hidden\":[128], \"lr\":1e-3},\n",
        "    {\"name\":\"mlp_128_lr5e-4\", \"hidden\":[128], \"lr\":5e-4},\n",
        "    {\"name\":\"mlp_256_lr1e-3\", \"hidden\":[256], \"lr\":1e-3},\n",
        "    {\"name\":\"mlp_256_lr5e-4\", \"hidden\":[256], \"lr\":5e-4},\n",
        "]\n",
        "\n",
        "def cv_score(config):\n",
        "    fold_scores = []\n",
        "    t0 = time.perf_counter()\n",
        "    for k,(tr,va) in enumerate(skf.split(X_all, y_all),1):\n",
        "        fk = time.perf_counter()\n",
        "        f1, _, _ = train_one_fold(X_all[tr], y_all[tr], X_all[va], y_all[va],\n",
        "                                  config, max_epochs=120, patience=12, bs=2048)\n",
        "        fold_scores.append(f1)\n",
        "        print(f\"{config['name']} | fold {k}/5  F1-macro={f1:.4f} | elapsed={time.perf_counter()-fk:.1f}s\")\n",
        "    print(f\"→ {config['name']} total={time.perf_counter()-t0:.1f}s\\n\")\n",
        "    return np.array(fold_scores)\n",
        "\n",
        "# roda grid\n",
        "grid_results = []\n",
        "for cfg in param_grid:\n",
        "    scores = cv_score(cfg)\n",
        "    grid_results.append({\"config\":cfg, \"mean\":scores.mean(), \"std\":scores.std(), \"per_fold\":scores.tolist()})\n",
        "grid_results = sorted(grid_results, key=lambda d: d[\"mean\"], reverse=True)\n",
        "\n",
        "best = grid_results[0]\n",
        "best_config = best[\"config\"]\n",
        "print(\"\\n>>> MELHOR CONFIG:\", best_config, f\"| F1-macro CV = {best['mean']:.4f} ± {best['std']:.4f}\")\n",
        "print(\"Resultados por fold (F1-macro):\", np.round(best[\"per_fold\"], 4))\n",
        "\n",
        "# OOF: treina por fold e grava predições nas posições corretas\n",
        "oof_pred = np.empty_like(y_all)\n",
        "fold_models, fold_scalers = [], []\n",
        "for k,(tr,va) in enumerate(skf.split(X_all, y_all),1):\n",
        "    f1, model, scaler = train_one_fold(X_all[tr], y_all[tr], X_all[va], y_all[va],\n",
        "                                       best_config, max_epochs=120, patience=12, bs=2048)\n",
        "    Xv = scaler.transform(X_all[va]).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        with AMP():\n",
        "            logits = model(torch.from_numpy(Xv)).argmax(1).numpy()\n",
        "    oof_pred[va] = logits\n",
        "    fold_models.append(model); fold_scalers.append(scaler)\n",
        "    print(f\"[OOF] fold {k}: F1-macro={f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report (OOF):\")\n",
        "print(classification_report(y_all, oof_pred, digits=4))\n",
        "cm = confusion_matrix(y_all, oof_pred)\n",
        "cm_df = pd.DataFrame(cm, index=[f\"true_{i}\" for i in range(n_classes)],\n",
        "                     columns=[f\"pred_{i}\" for i in range(n_classes)])\n",
        "cm_df.head()\n",
        "\n",
        "# salva um modelo\n",
        "final_scaler = StandardScaler().fit(X_all)\n",
        "X_full = final_scaler.transform(X_all).astype(np.float32)\n",
        "full_loader = DataLoader(TensorDataset(torch.from_numpy(X_full), torch.from_numpy(y_all)),\n",
        "                         batch_size=4096, shuffle=True)\n",
        "\n",
        "final = MLP(n_features, best_config[\"hidden\"], n_classes, dropout=0.2).to(DEVICE)\n",
        "opt = torch.optim.AdamW(final.parameters(), lr=best_config[\"lr\"], weight_decay=1e-4)\n",
        "scaler_amp = make_scaler()\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "for ep in range(20):  # treino curto só pra materializar o artefato\n",
        "    final.train()\n",
        "    for xb,yb in full_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with AMP():\n",
        "            loss = crit(final(xb), yb)\n",
        "        if scaler_amp is not None:\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "        else:\n",
        "            loss.backward(); opt.step()\n",
        "\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "torch.save(final.state_dict(), \"/content/models/best_mlp.pth\")\n",
        "import joblib\n",
        "joblib.dump(final_scaler, \"/content/models/best_scaler.pkl\")\n",
        "with open(\"/content/models/best_cv_summary.json\",\"w\") as f:\n",
        "    json.dump(best, f, indent=2)\n",
        "\n",
        "print(\"\\nArtefatos salvos em /content/models/: best_mlp.pth, best_scaler.pkl, best_cv_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhor solução.\n",
        "Após busca em grade com validação cruzada 5-fold, o modelo vencedor foi um MLP (256) com lr=1e-3. O desempenho médio foi F1-macro = 0.6759 ± 0.0197 (métricas por fold mostradas acima). O relatório OOF e a matriz de confusão confirmam generalização consistente entre as classes. O scaler e os pesos finais foram salvos para reuso."
      ],
      "metadata": {
        "id": "SuHDixmwBV_I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0sQ29RkAJBe"
      },
      "source": [
        "## Empacotando a solução\n",
        "\n",
        "Suponha que você deve entregar este classificador ao órgão responsável por administrar o Roosevelt National Park. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
        "\n",
        "1. Consulte a documentação a seguir:\n",
        "https://scikit-learn.org/stable/modules/model_persistence.html  \n",
        "2. Treine o modelo com todos os dados  \n",
        "3. Salve o modelo em disco  \n",
        "4. Construa uma rotina que recupere o modelo em disco  \n",
        "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gifMdf1eAJBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ea56f4-532d-4697-ddc6-1169517f52ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda | CUDA: True\n",
            "AMP: torch.amp\n",
            "best_config: {'name': 'mlp_256_lr1e-3', 'hidden': [256], 'lr': 0.001}\n",
            "Padronizando full…\n",
            "BATCH=8192 | EPOCHS=10 | workers=0\n"
          ]
        }
      ],
      "source": [
        "# EMPACOTAR\n",
        "import os, json, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# 0) GPU & AMP compat\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE, \"| CUDA:\", torch.cuda.is_available())\n",
        "\n",
        "USE_CUDA = (DEVICE.type == \"cuda\")\n",
        "try:\n",
        "    from torch import amp\n",
        "    def AMP(): return amp.autocast(\"cuda\", dtype=torch.float16) if USE_CUDA else nullcontext()\n",
        "    def make_scaler(): return amp.GradScaler(\"cuda\") if USE_CUDA else None\n",
        "    print(\"AMP: torch.amp\")\n",
        "except Exception:\n",
        "    from torch.cuda.amp import autocast as legacy_autocast, GradScaler as LegacyGradScaler\n",
        "    def AMP(): return legacy_autocast(enabled=USE_CUDA, dtype=torch.float16)\n",
        "    def make_scaler(): return LegacyGradScaler(enabled=USE_CUDA)\n",
        "    print(\"AMP: legacy\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 1) best_config\n",
        "if \"best_config\" not in globals():\n",
        "    with open(\"/content/models/best_cv_summary.json\") as f:\n",
        "        best = json.load(f)\n",
        "    best_config = best[\"config\"]\n",
        "print(\"best_config:\", best_config)\n",
        "\n",
        "# 2) dados\n",
        "if \"X_all\" not in globals() or \"y_all\" not in globals():\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_all = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_all = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "\n",
        "n_features = X_all.shape[1]\n",
        "# importante: usa número de classes distintas (não max+1)\n",
        "n_classes  = int(np.unique(y_all).shape[0])\n",
        "\n",
        "# 3) scaler + dataset\n",
        "print(\"Padronizando full…\")\n",
        "final_scaler = StandardScaler().fit(X_all)\n",
        "X_full = np.ascontiguousarray(final_scaler.transform(X_all).astype(np.float32))\n",
        "y_full = y_all.astype(int)\n",
        "\n",
        "BATCH_SIZE   = 8192 if USE_CUDA else 4096\n",
        "NUM_WORKERS  = 0\n",
        "EPOCHS_FINAL = min(best_config.get(\"epochs\", 20), 10)\n",
        "print(f\"BATCH={BATCH_SIZE} | EPOCHS={EPOCHS_FINAL} | workers={NUM_WORKERS}\")\n",
        "\n",
        "dl = DataLoader(\n",
        "    TensorDataset(torch.from_numpy(X_full), torch.from_numpy(y_full)),\n",
        "    batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=USE_CUDA\n",
        ")\n",
        "\n",
        "# 4) modelo\n",
        "assert \"MLP\" in globals(), \"Defina a classe MLP antes de executar esta célula.\"\n",
        "model = MLP(n_features, best_config[\"hidden\"], n_classes, dropout=best_config.get(\"dropout\", 0.2)).to(DEVICE)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config.get(\"wd\", 1e-4))\n",
        "crit = nn.CrossEntropyLoss()\n",
        "scaler_amp = make_scaler()\n",
        "\n",
        "# 5) treino com logs por época\n",
        "t0 = time.perf_counter()\n",
        "for ep in range(1, EPOCHS_FINAL + 1):\n",
        "    model.train(); losses = []; t_ep = time.perf_counter()\n",
        "    for i, (xb, yb) in enumerate(dl, 1):\n",
        "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with AMP():\n",
        "            loss = crit(model(xb), yb)\n",
        "        if scaler_amp is not None:\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "        else:\n",
        "            loss.backward(); opt.step()\n",
        "        losses.append(loss.item())\n",
        "        if i % 25 == 0 or i == len(dl):\n",
        "            print(f\"\\r[final] ep {ep}/{EPOCHS_FINAL} | step {i}/{len(dl)} | loss {np.mean(losses):.4f}\", end=\"\")\n",
        "    print(f\" | {time.perf_counter() - t_ep:.1f}s\")\n",
        "\n",
        "print(f\"Tempo total: {time.perf_counter() - t0:.1f}s\")\n",
        "\n",
        "# 6) salvar\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"/content/models/final_mlp.pth\")\n",
        "joblib.dump(final_scaler, \"/content/models/final_scaler.pkl\")\n",
        "meta = {\"n_features\": int(n_features), \"n_classes\": int(n_classes), \"best_config\": best_config}\n",
        "with open(\"/content/models/final_metadata.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"Salvo: final_mlp.pth, final_scaler.pkl, final_metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EMPACOTAR — verificação: carregar, prever full e gerar matriz de confusão (robusto a mismatch)\n",
        "import os, json, numpy as np, pandas as pd, torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "assert os.path.exists(\"/content/models/final_metadata.json\"), \"Rode a célula A primeiro.\"\n",
        "\n",
        "# metadata (pode estar com n_classes desatualizado; vamos confiar no checkpoint)\n",
        "with open(\"/content/models/final_metadata.json\") as f:\n",
        "    meta = json.load(f)\n",
        "best_config_loaded = meta[\"best_config\"]\n",
        "n_features_loaded  = meta[\"n_features\"]\n",
        "\n",
        "# carrega pesos\n",
        "state = torch.load(\"/content/models/final_mlp.pth\", map_location=\"cpu\")\n",
        "\n",
        "# infere out_dim pelo shape do último Linear no checkpoint\n",
        "# pega a última key que termina com \".weight\" (ordem preservada)\n",
        "last_w_key = [k for k in state.keys() if k.endswith(\".weight\")][-1]\n",
        "out_dim_ckpt = state[last_w_key].shape[0]\n",
        "\n",
        "# recria modelo com o out_dim do checkpoint e carrega pesos\n",
        "model_loaded = MLP(\n",
        "    n_features_loaded,\n",
        "    best_config_loaded[\"hidden\"],\n",
        "    out_dim_ckpt,\n",
        "    dropout=best_config_loaded.get(\"dropout\", 0.2),\n",
        ").to(\"cpu\")\n",
        "model_loaded.load_state_dict(state, strict=True)\n",
        "model_loaded.eval()\n",
        "\n",
        "# dados + scaler\n",
        "if \"X_all\" not in globals() or \"y_all\" not in globals():\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_all = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_all = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "\n",
        "scaler_loaded = joblib.load(\"/content/models/final_scaler.pkl\")\n",
        "X_inf = np.ascontiguousarray(scaler_loaded.transform(X_all).astype(np.float32))\n",
        "\n",
        "# inferência em lotes\n",
        "BS_PRED = 8192\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_inf), BS_PRED):\n",
        "        xb = torch.from_numpy(X_inf[i:i+BS_PRED])\n",
        "        preds.append(model_loaded(xb).argmax(1).numpy())\n",
        "y_pred = np.concatenate(preds)\n",
        "\n",
        "print(\"Classification report (FULL):\")\n",
        "print(classification_report(y_all, y_pred, digits=4))\n",
        "\n",
        "# matriz de confusão com labels reais (inclui 0 se o modelo usar)\n",
        "labels = np.unique(np.concatenate([y_all, y_pred]))\n",
        "cm = confusion_matrix(y_all, y_pred, labels=labels)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[f\"true_{c}\" for c in labels],\n",
        "    columns=[f\"pred_{c}\" for c in labels],\n",
        ")\n",
        "display(cm_df)\n",
        "\n",
        "# salvar\n",
        "os.makedirs(\"/content/reports\", exist_ok=True)\n",
        "cm_path = \"/content/reports/confusion_matrix_full.csv\"\n",
        "cm_df.to_csv(cm_path, index=True)\n",
        "print(\"Matriz salva em:\", cm_path)\n",
        "\n",
        "# atualiza metadata para refletir o out_dim real do checkpoint\n",
        "if meta.get(\"n_classes\", None) != int(out_dim_ckpt):\n",
        "    meta[\"n_classes\"] = int(out_dim_ckpt)\n",
        "    with open(\"/content/models/final_metadata.json\", \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "    print(f\"Metadata atualizado: n_classes = {int(out_dim_ckpt)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "LGQD3AkH6wZE",
        "outputId": "02ec3db4-49e0-4d7b-9d6a-1c810f955319"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (FULL):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.6946    0.6210    0.6557     21876\n",
            "           2     0.7055    0.8153    0.7564     29256\n",
            "           3     0.6092    0.8938    0.7246      3692\n",
            "           4     0.0000    0.0000    0.0000       284\n",
            "           5     0.0000    0.0000    0.0000       980\n",
            "           6     0.5222    0.0262    0.0499      1794\n",
            "           7     0.7130    0.3801    0.4958      2118\n",
            "\n",
            "    accuracy                         0.6931     60000\n",
            "   macro avg     0.4635    0.3909    0.3832     60000\n",
            "weighted avg     0.6755    0.6931    0.6715     60000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        pred_1  pred_2  pred_3  pred_4  pred_5  pred_6  pred_7\n",
              "true_1   13585    7990      15       0       0       0     286\n",
              "true_2    4712   23851     651       0       0       4      38\n",
              "true_3       0     377    3300       0       0      15       0\n",
              "true_4       0       0     260       0       0      24       0\n",
              "true_5      54     841      85       0       0       0       0\n",
              "true_6       1     646    1100       0       0      47       0\n",
              "true_7    1206     101       6       0       0       0     805"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37cd0e22-962f-4884-9de5-ecc59978a757\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_1</th>\n",
              "      <th>pred_2</th>\n",
              "      <th>pred_3</th>\n",
              "      <th>pred_4</th>\n",
              "      <th>pred_5</th>\n",
              "      <th>pred_6</th>\n",
              "      <th>pred_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>true_1</th>\n",
              "      <td>13585</td>\n",
              "      <td>7990</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_2</th>\n",
              "      <td>4712</td>\n",
              "      <td>23851</td>\n",
              "      <td>651</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_3</th>\n",
              "      <td>0</td>\n",
              "      <td>377</td>\n",
              "      <td>3300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>260</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_5</th>\n",
              "      <td>54</td>\n",
              "      <td>841</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_6</th>\n",
              "      <td>1</td>\n",
              "      <td>646</td>\n",
              "      <td>1100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_7</th>\n",
              "      <td>1206</td>\n",
              "      <td>101</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37cd0e22-962f-4884-9de5-ecc59978a757')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37cd0e22-962f-4884-9de5-ecc59978a757 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37cd0e22-962f-4884-9de5-ecc59978a757');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c5efb47-6b8f-4ca8-920d-43999cdbdc1a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c5efb47-6b8f-4ca8-920d-43999cdbdc1a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c5efb47-6b8f-4ca8-920d-43999cdbdc1a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3d67d8f9-882f-4ce8-acc6-99d40221d2bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cm_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3d67d8f9-882f-4ce8-acc6-99d40221d2bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cm_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cm_df",
              "summary": "{\n  \"name\": \"cm_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"pred_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5059,\n        \"min\": 0,\n        \"max\": 13585,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          13585,\n          4712,\n          1206\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8857,\n        \"min\": 0,\n        \"max\": 23851,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          7990,\n          23851,\n          646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1183,\n        \"min\": 6,\n        \"max\": 3300,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15,\n          651,\n          1100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 0,\n        \"max\": 47,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 302,\n        \"min\": 0,\n        \"max\": 805,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz salva em: /content/reports/confusion_matrix_full.csv\n",
            "Metadata atualizado: n_classes = 8\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
