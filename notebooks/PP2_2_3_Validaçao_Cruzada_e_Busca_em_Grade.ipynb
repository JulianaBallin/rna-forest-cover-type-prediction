{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVPf2qACAJBU"
      },
      "source": [
        "# Redes Neurais Artificiais 2025.2\n",
        "\n",
        "- **Disciplina**: Redes Neurais Artificiais 2025.2\n",
        "- **Professora**: Elloá B. Guedes (ebgcosta@uea.edu.br)  \n",
        "- **Github**: http://github.com/elloa  \n",
        "        \n",
        "\n",
        "Levando em conta a base de dados **_Forest Cover Type_**, esta parte do Projeto Prático diz respeito à proposição e avaliação de múltiplas redes neurais artificiais do tipo feedforward multilayer perceptron para o problema da classificação multi-classe da cobertura florestal em uma área do Roosevelt National Forest.\n",
        "\n",
        "## Busca em Grade\n",
        "\n",
        "Uma maneira padrão de escolher os parâmetros de um modelo de Machine Learning é por meio de uma busca em grade via força bruta. O algoritmo da busca em grade é dado como segue:\n",
        "\n",
        "1. Escolha a métrica de desempenho que você deseja maximizar  \n",
        "2. Escolha o algoritmo de Machine Learning (exemplo: redes neurais artificiais). Em seguida, defina os parâmetros ou hiperparâmetros deste tipo de modelo sobre os quais você dseja otimizar (número de épocas, taxa de aprendizado, etc.) e construa um array de valores a serem testados para cada parâmetro ou hiperparâmetro.  \n",
        "3. Defina a grade de busca, a qual é dada como o produto cartesiano de cada parâmetro a ser testado. Por exemplo, para os arrays [50, 100, 1000] e [10, 15], tem-se que a grade é [(50,10), (50,15), (100,10), (100,15), (1000,10), (1000,15)].\n",
        "4. Para cada combinação de parâmetros a serem otimizados, utilize o conjunto de treinamento para realizar uma validação cruzada (holdout ou k-fold) e calcule a métrica de avaliação no conjunto de teste (ou conjuntos de teste)\n",
        "5. Escolha a combinação de parâmetros que maximizam a métrica de avaliação. Este é o modelo otimizado.\n",
        "\n",
        "Por que esta abordagem funciona? Porque a busca em grade efetua uma pesquisa extensiva sobre as possíveis combinações de valores para cada um dos parâmetros a serem ajustados. Para cada combinação, ela estima a performance do modelo em dados novos. Por fim, o modelo com melhor métrica de desempenho é escolhido. Tem-se então que este modelo é o que melhor pode vir a generalizar mediante dados nunca antes vistos.\n",
        "\n",
        "## Efetuando a Busca em Grade sobre Hiperparâmetros das Top-6 RNAs\n",
        "\n",
        "Considerando a etapa anterior do projeto prático, foram identificadas pelo menos 6 melhores Redes Neurais para o problema da classificação multi-classe da cobertura florestal no conjunto de dados selecionado. Algumas destas redes possuem atributos categóricos como variáveis preditoras, enquanto outras possuem apenas os atributos numéricos como preditores.\n",
        "\n",
        "A primeira etapa desta segunda parte do projeto consiste em trazer para este notebook estas seis arquiteturas, ressaltando:\n",
        "\n",
        "1. Número de neurônios ocultos por camada  \n",
        "2. Função de Ativação  \n",
        "3. Utilização ou não de atributos categóricos   \n",
        "4. Desempenho médio +- desvio padrão nos testes anteriores  \n",
        "5. Número de repetições que a equipe conseguiu realizar para verificar os resultados  \n",
        "\n",
        "Elabore uma busca em grade sobre estas arquiteturas que contemple variações nos hiperparâmetros a seguir, conforme documentação de [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
        "\n",
        "A. Solver  (Não usar o LBFGS, pois é mais adequado para datasets pequenos)  \n",
        "B. Batch Size  \n",
        "C. Learning Rate Init  \n",
        "D. Paciência (n_iter_no_change)  \n",
        "E. Épocas  \n",
        "\n",
        "Nesta busca em grande, contemple a utilização do objeto [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYN5DbptAJBW"
      },
      "source": [
        "## Validação Cruzada k-fold\n",
        "\n",
        "Na elaboração da busca em grid, vamos avaliar os modelos propostos segundo uma estratégia de validação cruzada ainda não explorada até o momento: a validação cruzada k-fold. Segundo a mesma, o conjunto de dados é particionado em k partes: a cada iteração, separa-se uma das partes para teste e o modelo é treinado com as k-1 partes remanescentes. Valores sugestivos de k na literatura são k = 3, 5 ou 10, pois o custo computacional desta validação dos modelos é alto. A métrica de desempenho é resultante da média dos desempenhos nas k iterações. A figura a seguir ilustra a ideia desta avaliação\n",
        "\n",
        "<img src = \"https://ethen8181.github.io/machine-learning/model_selection/img/kfolds.png\" width=600></img>\n",
        "\n",
        "Considerando a métrica de desempenho F1-Score, considere a validação cruzada 5-fold para aferir os resultados da busca em grande anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIwpixvWH8iN",
        "outputId": "3c99f691-e495-4b6a-9248-d5ceae855088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn torch torchvision torchaudio kagglehub ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gjrfZklAJBY",
        "outputId": "f9b5d101-2402-4466-bc68-0fd21aa5c129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset baixado em: /kaggle/input/forest-cover-type-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Baixar o dataset do Kaggle\n",
        "path = kagglehub.dataset_download(\"uciml/forest-cover-type-dataset\")\n",
        "print(\"Dataset baixado em:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Bojm2PAJBZ",
        "outputId": "55f61131-5e8b-4e11-e397-1164f4d56651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some files in /kaggle/input/forest-cover-type-dataset:\n",
            "['/kaggle/input/forest-cover-type-dataset/covtype.csv']\n",
            "Using CSV_PATH = /kaggle/input/forest-cover-type-dataset/covtype.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell A — locate dataset in Colab cache\n",
        "import os, pprint, glob\n",
        "candidates = glob.glob('/kaggle/input/forest-cover-type-dataset/**', recursive=True)\n",
        "files = [p for p in candidates if os.path.isfile(p)]\n",
        "print(\"Some files in /kaggle/input/forest-cover-type-dataset:\")\n",
        "pprint.pprint(files[:20])\n",
        "# Common CSV path:\n",
        "CSV_PATH = '/kaggle/input/forest-cover-type-dataset/covtype.csv'\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    # fallback: find any covtype*.csv\n",
        "    import glob\n",
        "    found = glob.glob('/kaggle/input/**/covtype*.csv', recursive=True)\n",
        "    if found:\n",
        "        CSV_PATH = found[0]\n",
        "    else:\n",
        "        raise FileNotFoundError(\"covtype.csv not found in /kaggle/input; check files list above.\")\n",
        "print(\"Using CSV_PATH =\", CSV_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "n0sKFvJQAJBa",
        "outputId": "d318c5a1-29c3-45d7-a934-b316ccdd2687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded df shape: (581012, 55)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-586841b5-f4bf-48f4-a48a-c3acf762c9e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-586841b5-f4bf-48f4-a48a-c3acf762c9e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-586841b5-f4bf-48f4-a48a-c3acf762c9e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-586841b5-f4bf-48f4-a48a-c3acf762c9e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-865af71e-0bc5-49a6-acfb-1322bdfa6b17\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-865af71e-0bc5-49a6-acfb-1322bdfa6b17')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-865af71e-0bc5-49a6-acfb-1322bdfa6b17 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
              "0       2596      51      3                               258   \n",
              "1       2590      56      2                               212   \n",
              "2       2804     139      9                               268   \n",
              "3       2785     155     18                               242   \n",
              "4       2595      45      2                               153   \n",
              "\n",
              "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
              "0                               0                              510   \n",
              "1                              -6                              390   \n",
              "2                              65                             3180   \n",
              "3                             118                             3090   \n",
              "4                              -1                              391   \n",
              "\n",
              "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
              "0            221             232            148   \n",
              "1            220             235            151   \n",
              "2            234             238            135   \n",
              "3            238             238            122   \n",
              "4            220             234            150   \n",
              "\n",
              "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
              "0                                6279  ...            0            0   \n",
              "1                                6225  ...            0            0   \n",
              "2                                6121  ...            0            0   \n",
              "3                                6211  ...            0            0   \n",
              "4                                6172  ...            0            0   \n",
              "\n",
              "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
              "0            0            0            0            0            0   \n",
              "1            0            0            0            0            0   \n",
              "2            0            0            0            0            0   \n",
              "3            0            0            0            0            0   \n",
              "4            0            0            0            0            0   \n",
              "\n",
              "   Soil_Type39  Soil_Type40  Cover_Type  \n",
              "0            0            0           5  \n",
              "1            0            0           5  \n",
              "2            0            0           2  \n",
              "3            0            0           2  \n",
              "4            0            0           5  \n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns (first 20): ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5', 'Soil_Type6']\n"
          ]
        }
      ],
      "source": [
        "# Cell B — load CSV and quick inspect\n",
        "import pandas as pd\n",
        "CSV_PATH = '/kaggle/input/forest-cover-type-dataset/covtype.csv'  # adjust if needed\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Loaded df shape:\", df.shape)\n",
        "display(df.head())\n",
        "print(\"Columns (first 20):\", df.columns.tolist()[:20])\n",
        "# configure sample size: None to use all data (careful!), or integer to subsample stratified\n",
        "MAX_SAMPLES = None   # safe default for Colab; set to None to use full dataset if you have time/ram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e9hB6ixAJBb",
        "outputId": "b5c2fe36-ed7a-4e59-a428-f834da5de869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target column: Cover_Type\n",
            "Original dataset size: (581012, 54)\n",
            "Using sample shape: (581012, 54) n_classes: 7\n"
          ]
        }
      ],
      "source": [
        "# Cell C — prepare X, y and optional stratified sampling\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "target_col = 'Cover_Type' if 'Cover_Type' in df.columns else df.columns[-1]\n",
        "print(\"Target column:\", target_col)\n",
        "X = df.drop(columns=[target_col]).values.astype(np.float32)\n",
        "y = df[target_col].values.astype(np.int64)\n",
        "# convert labels from 1..7 to 0..6 if needed\n",
        "if y.min() == 1:\n",
        "    y = y - 1\n",
        "\n",
        "print(\"Original dataset size:\", X.shape)\n",
        "\n",
        "if MAX_SAMPLES is not None and X.shape[0] > MAX_SAMPLES:\n",
        "    print(f\"Stratified sampling to {MAX_SAMPLES} samples...\")\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=MAX_SAMPLES, random_state=42)\n",
        "    for _, idx in sss.split(X, y):\n",
        "        X_sample = X[idx]\n",
        "        y_sample = y[idx]\n",
        "else:\n",
        "    X_sample, y_sample = X, y\n",
        "\n",
        "print(\"Using sample shape:\", X_sample.shape, \"n_classes:\", len(np.unique(y_sample)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM9goNh9Hxee",
        "outputId": "0259f16c-f357-4975-d22a-c69a69862066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell D — PyTorch helpers\n",
        "import torch, gc\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, max(hidden_dim//2, 8)),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(max(hidden_dim//2, 8), n_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, yb in loader:\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(Xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * Xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb = Xb.to(device)\n",
        "            logits = model(Xb)\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            ps.append(preds)\n",
        "            ys.append(yb.numpy())\n",
        "    y_true = np.concatenate(ys)\n",
        "    y_pred = np.concatenate(ps)\n",
        "    return float(f1_score(y_true, y_pred, average='weighted')), y_true, y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kO9QDi7YKe-",
        "outputId": "5ade6be6-9a88-4616-fa7f-e640fad53220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_dim: 54 n_classes: 7\n",
            "Testing cfg: {'hidden_dim': 128, 'lr': 0.001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.8335 (time 281.8s)\n",
            "Testing cfg: {'hidden_dim': 128, 'lr': 0.0001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.7600 (time 265.8s)\n",
            "Testing cfg: {'hidden_dim': 256, 'lr': 0.001, 'batch_size': 256, 'epochs': 8}\n",
            "  Mean F1 5-fold = 0.8662 (time 264.3s)\n",
            "Testing cfg: {'hidden_dim': 256, 'lr': 0.0001, 'batch_size': 256, 'epochs': 8}\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-783442466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mf1_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-7-1844854758.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Cell E — grid search manual (small grid); adjust param_grid for more experiments\n",
        "import time, itertools, json\n",
        "from copy import deepcopy\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import gc\n",
        "\n",
        "n_classes = len(np.unique(y_sample))\n",
        "input_dim = X_sample.shape[1]\n",
        "print(\"input_dim:\", input_dim, \"n_classes:\", n_classes)\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_dim': [128, 256],\n",
        "    'lr': [1e-3, 1e-4],\n",
        "    'batch_size': [256],\n",
        "    'epochs': [8]\n",
        "}\n",
        "\n",
        "def iter_grid(grid):\n",
        "    keys = list(grid.keys())\n",
        "    for vals in itertools.product(*(grid[k] for k in keys)):\n",
        "        yield dict(zip(keys, vals))\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_cfg, best_score = None, -1.0\n",
        "results = []\n",
        "\n",
        "for cfg in iter_grid(param_grid):\n",
        "    fold_scores = []\n",
        "    t0 = time.time()\n",
        "    print(\"Testing cfg:\", cfg)\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_sample, y_sample), 1):\n",
        "        # fit scaler on train fold\n",
        "        scaler = StandardScaler()\n",
        "        X_train_fold = scaler.fit_transform(X_sample[train_idx])\n",
        "        X_val_fold = scaler.transform(X_sample[val_idx])\n",
        "        y_train_fold = y_sample[train_idx]\n",
        "        y_val_fold = y_sample[val_idx]\n",
        "\n",
        "        train_ds = NumpyDataset(X_train_fold, y_train_fold)\n",
        "        val_ds = NumpyDataset(X_val_fold, y_val_fold)\n",
        "        train_loader = DataLoader(train_ds, batch_size=cfg['batch_size'], shuffle=True)\n",
        "        val_loader = DataLoader(val_ds, batch_size=cfg['batch_size'], shuffle=False)\n",
        "\n",
        "        model = MLP(input_dim=input_dim, hidden_dim=cfg['hidden_dim'], n_classes=n_classes).to(device)\n",
        "        opt = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for ep in range(cfg['epochs']):\n",
        "            _ = train_one_epoch(model, train_loader, opt, criterion)\n",
        "\n",
        "        f1_val, _, _ = eval_model(model, val_loader)\n",
        "        fold_scores.append(f1_val)\n",
        "\n",
        "        # cleanup\n",
        "        del model, opt, criterion, train_loader, val_loader, train_ds, val_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    mean_f1 = float(np.mean(fold_scores))\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"  Mean F1 5-fold = {mean_f1:.4f} (time {elapsed:.1f}s)\")\n",
        "    results.append((cfg, mean_f1))\n",
        "    if mean_f1 > best_score:\n",
        "        best_score = mean_f1\n",
        "        best_cfg = deepcopy(cfg)\n",
        "\n",
        "print(\"\\nBest config:\", best_cfg, \"best_cv_f1 =\", best_score)\n",
        "# save results\n",
        "with open('/content/grid_search_results.json', 'w') as f:\n",
        "    json.dump({'best': best_cfg, 'best_score': best_score, 'results': [[r[0], r[1]] for r in results]}, f, indent=2)\n",
        "print(\"Saved grid search summary to /content/grid_search_results.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA7c50uTYQPf"
      },
      "outputs": [],
      "source": [
        "# Cell F — train final on X_sample with scaler + save model & scaler\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "best = best_cfg\n",
        "print(\"Training final with:\", best)\n",
        "\n",
        "scaler_final = StandardScaler()\n",
        "X_scaled = scaler_final.fit_transform(X_sample)\n",
        "y_final = y_sample\n",
        "\n",
        "final_ds = NumpyDataset(X_scaled, y_final)\n",
        "final_loader = DataLoader(final_ds, batch_size=best['batch_size'], shuffle=True)\n",
        "\n",
        "model_final = MLP(input_dim=input_dim, hidden_dim=best['hidden_dim'], n_classes=n_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model_final.parameters(), lr=best['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(best['epochs']):\n",
        "    loss = train_one_epoch(model_final, final_loader, optimizer, criterion)\n",
        "    print(f\"Epoch {epoch+1}/{best['epochs']} - loss: {loss:.4f}\")\n",
        "\n",
        "MODEL_PATH = '/content/cover_mlp_best.pth'\n",
        "SCALER_PATH = '/content/cover_scaler.pkl'\n",
        "torch.save(model_final.state_dict(), MODEL_PATH)\n",
        "joblib.dump(scaler_final, SCALER_PATH)\n",
        "print(\"Saved model to\", MODEL_PATH)\n",
        "print(\"Saved scaler to\", SCALER_PATH)\n",
        "\n",
        "# save summary\n",
        "summary = {\n",
        "    'n_total_available': int(X.shape[0]),\n",
        "    'n_used_sample': int(X_sample.shape[0]),\n",
        "    'best_cfg': best,\n",
        "    'best_cv_f1': best_score,\n",
        "    'model_path': MODEL_PATH,\n",
        "    'scaler_path': SCALER_PATH\n",
        "}\n",
        "import json\n",
        "with open('/content/cover_training_summary.json', 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "print(\"Saved training summary to /content/cover_training_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axxjZKd_AJBb"
      },
      "source": [
        "## Identificando a mellhor solução\n",
        "\n",
        "Como resultado da busca em grande com validação cruzada 5-fold, identifique o modelo otimizado com melhor desempenho para o problema. Apresente claramente este modelo, seus parâmetros, hiperparâmetros otimizados e resultados para cada um dos folds avaliados. Esta é a melhor solução identificada em decorrência deste projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56vl-eZyAJBc"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, json, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try: torch.set_float32_matmul_precision(\"high\")\n",
        "except: pass\n",
        "\n",
        "# Descobre X/y vindos do notebook; senão usa covertype da sklearn\n",
        "def _pick_xy():\n",
        "    for Xn, yn in [(\"Xcv\",\"ycv\"), (\"X_use\",\"y_use\"), (\"X\",\"y\")]:\n",
        "        if Xn in globals() and yn in globals():\n",
        "            X_, y_ = globals()[Xn], globals()[yn]\n",
        "            return np.asarray(X_, dtype=np.float32), np.asarray(y_, dtype=int)\n",
        "    # fallback: covertype\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_ = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_ = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "    # amostra pra caber no Colab se precisar\n",
        "    if X_.shape[0] > 60000:\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        X_, _, y_, _ = train_test_split(X_, y_, train_size=60000, stratify=y_, random_state=42)\n",
        "    return X_.astype(np.float32), y_\n",
        "\n",
        "X_all, y_all = _pick_xy()\n",
        "n_features = X_all.shape[1]; n_classes = int(np.max(y_all))+1\n",
        "print(f\"Dados: X={X_all.shape}, y={y_all.shape}, classes={n_classes}, device={DEVICE}\")\n",
        "\n",
        "# Modelo MLP simples\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers, d = [], in_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(d, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            d = h\n",
        "        layers += [nn.Linear(d, out_dim)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "def train_one_fold(X_tr, y_tr, X_va, y_va, config, max_epochs=200, patience=15, bs=2048):\n",
        "    # scaler por fold\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    Xt = scaler.transform(X_tr).astype(np.float32)\n",
        "    Xv = scaler.transform(X_va).astype(np.float32)\n",
        "\n",
        "    tl = DataLoader(TensorDataset(torch.from_numpy(Xt), torch.from_numpy(y_tr)), batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    vl = DataLoader(TensorDataset(torch.from_numpy(Xv), torch.from_numpy(y_va)), batch_size=bs, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = MLP(n_features, config[\"hidden\"], n_classes, dropout=config.get(\"dropout\",0.2)).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config.get(\"wd\",1e-4))\n",
        "    scaler_amp = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_f1, best_state, noimp = -1.0, None, 0\n",
        "    for ep in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        for xb, yb in tl:\n",
        "            xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE.type==\"cuda\")):\n",
        "                loss = crit(model(xb), yb)\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "\n",
        "        # valida\n",
        "        model.eval(); preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in vl:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(DEVICE.type==\"cuda\")):\n",
        "                    p = model(xb).argmax(1).cpu()\n",
        "                preds.append(p); gts.append(yb)\n",
        "        yv = torch.cat(gts).numpy(); pv = torch.cat(preds).numpy()\n",
        "        f1 = f1_score(yv, pv, average=\"macro\")\n",
        "\n",
        "        if f1 > best_f1 + 1e-4:\n",
        "            best_f1, noimp = f1, 0\n",
        "            best_state = {k: v.cpu() for k,v in model.state_dict().items()}\n",
        "        else:\n",
        "            noimp += 1\n",
        "            if noimp >= patience: break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_f1, model.cpu(), scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E9SBFNFAJBd"
      },
      "outputs": [],
      "source": [
        "import time, json, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "from contextlib import nullcontext\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "USE_CUDA = (DEVICE.type == \"cuda\")\n",
        "\n",
        "try:\n",
        "    from torch import amp\n",
        "    def AMP():\n",
        "        return amp.autocast(\"cuda\", dtype=torch.float16) if USE_CUDA else nullcontext()\n",
        "    def make_scaler():\n",
        "        return amp.GradScaler(\"cuda\") if USE_CUDA else None\n",
        "    print(\"AMP: usando torch.amp ✓\")\n",
        "except Exception:\n",
        "    from torch.cuda.amp import autocast as legacy_autocast, GradScaler as LegacyGradScaler\n",
        "    def AMP():\n",
        "        return legacy_autocast(enabled=USE_CUDA, dtype=torch.float16)\n",
        "    def make_scaler():\n",
        "        return LegacyGradScaler(enabled=USE_CUDA)\n",
        "    print(\"AMP: usando torch.cuda.amp (legacy) ✓\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try: torch.set_float32_matmul_precision(\"high\")\n",
        "except: pass\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "assert \"X_all\" in globals() and \"y_all\" in globals(), \"Cadê X_all/y_all? Rode a célula G1 antes.\"\n",
        "assert \"n_features\" in globals() and \"n_classes\" in globals(), \"Cadê n_features/n_classes? Rode a célula G1 antes.\"\n",
        "assert \"MLP\" in globals(), \"Cadê a classe MLP? Ela é definida na G1.\"\n",
        "\n",
        "# função de treino\n",
        "def train_one_fold(X_tr, y_tr, X_va, y_va, config, max_epochs=120, patience=12, bs=2048):\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    Xt = scaler.transform(X_tr).astype(np.float32)\n",
        "    Xv = scaler.transform(X_va).astype(np.float32)\n",
        "\n",
        "    tl = DataLoader(TensorDataset(torch.from_numpy(Xt), torch.from_numpy(y_tr)), batch_size=bs, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    vl = DataLoader(TensorDataset(torch.from_numpy(Xv), torch.from_numpy(y_va)), batch_size=bs, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = MLP(n_features, config[\"hidden\"], n_classes, dropout=config.get(\"dropout\", 0.2)).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config.get(\"wd\", 1e-4))\n",
        "    scaler_amp = make_scaler()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_f1, noimp, best_state = -1.0, 0, None\n",
        "    for ep in range(1, max_epochs + 1):\n",
        "        # treino\n",
        "        model.train()\n",
        "        for xb, yb in tl:\n",
        "            xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with AMP():\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "            if scaler_amp is not None:\n",
        "                scaler_amp.scale(loss).backward()\n",
        "                scaler_amp.step(opt)\n",
        "                scaler_amp.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "        # validação\n",
        "        model.eval(); preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in vl:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                with AMP():\n",
        "                    p = model(xb).argmax(1).cpu()\n",
        "                preds.append(p); gts.append(yb)\n",
        "        yv = torch.cat(gts).numpy(); pv = torch.cat(preds).numpy()\n",
        "        f1 = f1_score(yv, pv, average=\"macro\")\n",
        "\n",
        "        if f1 > best_f1 + 1e-4:\n",
        "            best_f1, noimp = f1, 0\n",
        "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            noimp += 1\n",
        "            if noimp >= patience:\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_f1, model.cpu(), scaler\n",
        "\n",
        "# =====================================================================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "param_grid = [\n",
        "    {\"name\":\"mlp_128_lr1e-3\", \"hidden\":[128], \"lr\":1e-3},\n",
        "    {\"name\":\"mlp_128_lr5e-4\", \"hidden\":[128], \"lr\":5e-4},\n",
        "    {\"name\":\"mlp_256_lr1e-3\", \"hidden\":[256], \"lr\":1e-3},\n",
        "    {\"name\":\"mlp_256_lr5e-4\", \"hidden\":[256], \"lr\":5e-4},\n",
        "]\n",
        "\n",
        "def cv_score(config):\n",
        "    fold_scores = []\n",
        "    t0 = time.perf_counter()\n",
        "    for k,(tr,va) in enumerate(skf.split(X_all, y_all),1):\n",
        "        fk = time.perf_counter()\n",
        "        f1, _, _ = train_one_fold(X_all[tr], y_all[tr], X_all[va], y_all[va],\n",
        "                                  config, max_epochs=120, patience=12, bs=2048)\n",
        "        fold_scores.append(f1)\n",
        "        print(f\"{config['name']} | fold {k}/5  F1-macro={f1:.4f} | elapsed={time.perf_counter()-fk:.1f}s\")\n",
        "    print(f\"→ {config['name']} total={time.perf_counter()-t0:.1f}s\\n\")\n",
        "    return np.array(fold_scores)\n",
        "\n",
        "# roda grid\n",
        "grid_results = []\n",
        "for cfg in param_grid:\n",
        "    scores = cv_score(cfg)\n",
        "    grid_results.append({\"config\":cfg, \"mean\":scores.mean(), \"std\":scores.std(), \"per_fold\":scores.tolist()})\n",
        "grid_results = sorted(grid_results, key=lambda d: d[\"mean\"], reverse=True)\n",
        "\n",
        "best = grid_results[0]\n",
        "best_config = best[\"config\"]\n",
        "print(\"\\n>>> MELHOR CONFIG:\", best_config, f\"| F1-macro CV = {best['mean']:.4f} ± {best['std']:.4f}\")\n",
        "print(\"Resultados por fold (F1-macro):\", np.round(best[\"per_fold\"], 4))\n",
        "\n",
        "# OOF: treina por fold e grava predições nas posições corretas\n",
        "oof_pred = np.empty_like(y_all)\n",
        "fold_models, fold_scalers = [], []\n",
        "for k,(tr,va) in enumerate(skf.split(X_all, y_all),1):\n",
        "    f1, model, scaler = train_one_fold(X_all[tr], y_all[tr], X_all[va], y_all[va],\n",
        "                                       best_config, max_epochs=120, patience=12, bs=2048)\n",
        "    Xv = scaler.transform(X_all[va]).astype(np.float32)\n",
        "    with torch.no_grad():\n",
        "        with AMP():\n",
        "            logits = model(torch.from_numpy(Xv)).argmax(1).numpy()\n",
        "    oof_pred[va] = logits\n",
        "    fold_models.append(model); fold_scalers.append(scaler)\n",
        "    print(f\"[OOF] fold {k}: F1-macro={f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification report (OOF):\")\n",
        "print(classification_report(y_all, oof_pred, digits=4))\n",
        "cm = confusion_matrix(y_all, oof_pred)\n",
        "cm_df = pd.DataFrame(cm, index=[f\"true_{i}\" for i in range(n_classes)],\n",
        "                     columns=[f\"pred_{i}\" for i in range(n_classes)])\n",
        "cm_df.head()\n",
        "\n",
        "# salva um modelo\n",
        "final_scaler = StandardScaler().fit(X_all)\n",
        "X_full = final_scaler.transform(X_all).astype(np.float32)\n",
        "full_loader = DataLoader(TensorDataset(torch.from_numpy(X_full), torch.from_numpy(y_all)),\n",
        "                         batch_size=4096, shuffle=True)\n",
        "\n",
        "final = MLP(n_features, best_config[\"hidden\"], n_classes, dropout=0.2).to(DEVICE)\n",
        "opt = torch.optim.AdamW(final.parameters(), lr=best_config[\"lr\"], weight_decay=1e-4)\n",
        "scaler_amp = make_scaler()\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "for ep in range(20):  # treino curto só pra materializar o artefato\n",
        "    final.train()\n",
        "    for xb,yb in full_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with AMP():\n",
        "            loss = crit(final(xb), yb)\n",
        "        if scaler_amp is not None:\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "        else:\n",
        "            loss.backward(); opt.step()\n",
        "\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "torch.save(final.state_dict(), \"/content/models/best_mlp.pth\")\n",
        "import joblib\n",
        "joblib.dump(final_scaler, \"/content/models/best_scaler.pkl\")\n",
        "with open(\"/content/models/best_cv_summary.json\",\"w\") as f:\n",
        "    json.dump(best, f, indent=2)\n",
        "\n",
        "print(\"\\nArtefatos salvos em /content/models/: best_mlp.pth, best_scaler.pkl, best_cv_summary.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuHDixmwBV_I"
      },
      "source": [
        "Melhor solução.\n",
        "Após busca em grade com validação cruzada 5-fold, o modelo vencedor foi um MLP (256) com lr=1e-3. O desempenho médio foi F1-macro = 0.6759 ± 0.0197 (métricas por fold mostradas acima). O relatório OOF e a matriz de confusão confirmam generalização consistente entre as classes. O scaler e os pesos finais foram salvos para reuso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0sQ29RkAJBe"
      },
      "source": [
        "## Empacotando a solução\n",
        "\n",
        "Suponha que você deve entregar este classificador ao órgão responsável por administrar o Roosevelt National Park. Para tanto, você deve fazer uma preparação do mesmo para utilização neste cenário. Uma vez que já identificou os melhores parâmetros e hiperparâmetros, o passo remanescente consiste em treinar o modelo com estes valores e todos os dados disponíveis, salvando o conjunto de pesos do modelo ao final para entrega ao cliente. Assim, finalize o projeto prático realizando tais passos.\n",
        "\n",
        "1. Consulte a documentação a seguir:\n",
        "https://scikit-learn.org/stable/modules/model_persistence.html  \n",
        "2. Treine o modelo com todos os dados  \n",
        "3. Salve o modelo em disco  \n",
        "4. Construa uma rotina que recupere o modelo em disco  \n",
        "5. Mostre que a rotina é funcional, fazendo previsões com todos os elementos do dataset e exibindo uma matriz de confusão das mesmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gifMdf1eAJBg"
      },
      "outputs": [],
      "source": [
        "# EMPACOTAR\n",
        "import os, json, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "from contextlib import nullcontext\n",
        "\n",
        "# 0) GPU & AMP compat\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE, \"| CUDA:\", torch.cuda.is_available())\n",
        "\n",
        "USE_CUDA = (DEVICE.type == \"cuda\")\n",
        "try:\n",
        "    from torch import amp\n",
        "    def AMP(): return amp.autocast(\"cuda\", dtype=torch.float16) if USE_CUDA else nullcontext()\n",
        "    def make_scaler(): return amp.GradScaler(\"cuda\") if USE_CUDA else None\n",
        "    print(\"AMP: torch.amp\")\n",
        "except Exception:\n",
        "    from torch.cuda.amp import autocast as legacy_autocast, GradScaler as LegacyGradScaler\n",
        "    def AMP(): return legacy_autocast(enabled=USE_CUDA, dtype=torch.float16)\n",
        "    def make_scaler(): return LegacyGradScaler(enabled=USE_CUDA)\n",
        "    print(\"AMP: legacy\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 1) best_config\n",
        "if \"best_config\" not in globals():\n",
        "    with open(\"/content/models/best_cv_summary.json\") as f:\n",
        "        best = json.load(f)\n",
        "    best_config = best[\"config\"]\n",
        "print(\"best_config:\", best_config)\n",
        "\n",
        "# 2) dados\n",
        "if \"X_all\" not in globals() or \"y_all\" not in globals():\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_all = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_all = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "\n",
        "n_features = X_all.shape[1]\n",
        "# importante: usa número de classes distintas (não max+1)\n",
        "n_classes  = int(np.unique(y_all).shape[0])\n",
        "\n",
        "# 3) scaler + dataset\n",
        "print(\"Padronizando full…\")\n",
        "final_scaler = StandardScaler().fit(X_all)\n",
        "X_full = np.ascontiguousarray(final_scaler.transform(X_all).astype(np.float32))\n",
        "y_full = y_all.astype(int)\n",
        "\n",
        "BATCH_SIZE   = 8192 if USE_CUDA else 4096\n",
        "NUM_WORKERS  = 0\n",
        "EPOCHS_FINAL = min(best_config.get(\"epochs\", 20), 10)\n",
        "print(f\"BATCH={BATCH_SIZE} | EPOCHS={EPOCHS_FINAL} | workers={NUM_WORKERS}\")\n",
        "\n",
        "dl = DataLoader(\n",
        "    TensorDataset(torch.from_numpy(X_full), torch.from_numpy(y_full)),\n",
        "    batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=USE_CUDA\n",
        ")\n",
        "\n",
        "# 4) modelo\n",
        "assert \"MLP\" in globals(), \"Defina a classe MLP antes de executar esta célula.\"\n",
        "model = MLP(n_features, best_config[\"hidden\"], n_classes, dropout=best_config.get(\"dropout\", 0.2)).to(DEVICE)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config.get(\"wd\", 1e-4))\n",
        "crit = nn.CrossEntropyLoss()\n",
        "scaler_amp = make_scaler()\n",
        "\n",
        "# 5) treino com logs por época\n",
        "t0 = time.perf_counter()\n",
        "for ep in range(1, EPOCHS_FINAL + 1):\n",
        "    model.train(); losses = []; t_ep = time.perf_counter()\n",
        "    for i, (xb, yb) in enumerate(dl, 1):\n",
        "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with AMP():\n",
        "            loss = crit(model(xb), yb)\n",
        "        if scaler_amp is not None:\n",
        "            scaler_amp.scale(loss).backward(); scaler_amp.step(opt); scaler_amp.update()\n",
        "        else:\n",
        "            loss.backward(); opt.step()\n",
        "        losses.append(loss.item())\n",
        "        if i % 25 == 0 or i == len(dl):\n",
        "            print(f\"\\r[final] ep {ep}/{EPOCHS_FINAL} | step {i}/{len(dl)} | loss {np.mean(losses):.4f}\", end=\"\")\n",
        "    print(f\" | {time.perf_counter() - t_ep:.1f}s\")\n",
        "\n",
        "print(f\"Tempo total: {time.perf_counter() - t0:.1f}s\")\n",
        "\n",
        "# 6) salvar\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "torch.save(model.state_dict(), \"/content/models/final_mlp.pth\")\n",
        "joblib.dump(final_scaler, \"/content/models/final_scaler.pkl\")\n",
        "meta = {\"n_features\": int(n_features), \"n_classes\": int(n_classes), \"best_config\": best_config}\n",
        "with open(\"/content/models/final_metadata.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print(\"Salvo: final_mlp.pth, final_scaler.pkl, final_metadata.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQD3AkH6wZE"
      },
      "outputs": [],
      "source": [
        "# EMPACOTAR — verificação: carregar, prever full e gerar matriz de confusão\n",
        "import os, json, numpy as np, pandas as pd, torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "assert os.path.exists(\"/content/models/final_metadata.json\"), \"Rode a célula A primeiro.\"\n",
        "\n",
        "# metadata (pode estar com n_classes desatualizado; vamos confiar no checkpoint)\n",
        "with open(\"/content/models/final_metadata.json\") as f:\n",
        "    meta = json.load(f)\n",
        "best_config_loaded = meta[\"best_config\"]\n",
        "n_features_loaded  = meta[\"n_features\"]\n",
        "\n",
        "# carrega pesos\n",
        "state = torch.load(\"/content/models/final_mlp.pth\", map_location=\"cpu\")\n",
        "\n",
        "# infere out_dim pelo shape do último Linear no checkpoint\n",
        "# pega a última key que termina com \".weight\" (ordem preservada)\n",
        "last_w_key = [k for k in state.keys() if k.endswith(\".weight\")][-1]\n",
        "out_dim_ckpt = state[last_w_key].shape[0]\n",
        "\n",
        "# recria modelo com o out_dim do checkpoint e carrega pesos\n",
        "model_loaded = MLP(\n",
        "    n_features_loaded,\n",
        "    best_config_loaded[\"hidden\"],\n",
        "    out_dim_ckpt,\n",
        "    dropout=best_config_loaded.get(\"dropout\", 0.2),\n",
        ").to(\"cpu\")\n",
        "model_loaded.load_state_dict(state, strict=True)\n",
        "model_loaded.eval()\n",
        "\n",
        "# dados + scaler\n",
        "if \"X_all\" not in globals() or \"y_all\" not in globals():\n",
        "    from sklearn.datasets import fetch_covtype\n",
        "    df = fetch_covtype(as_frame=True).frame\n",
        "    y_all = df[\"Cover_Type\"].astype(int).to_numpy()\n",
        "    X_all = df.drop(columns=[\"Cover_Type\"]).to_numpy(dtype=np.float32)\n",
        "\n",
        "scaler_loaded = joblib.load(\"/content/models/final_scaler.pkl\")\n",
        "X_inf = np.ascontiguousarray(scaler_loaded.transform(X_all).astype(np.float32))\n",
        "\n",
        "# inferência em lotes\n",
        "BS_PRED = 8192\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_inf), BS_PRED):\n",
        "        xb = torch.from_numpy(X_inf[i:i+BS_PRED])\n",
        "        preds.append(model_loaded(xb).argmax(1).numpy())\n",
        "y_pred = np.concatenate(preds)\n",
        "\n",
        "print(\"Classification report (FULL):\")\n",
        "print(classification_report(y_all, y_pred, digits=4))\n",
        "\n",
        "# matriz de confusão com labels reais (inclui 0 se o modelo usar)\n",
        "labels = np.unique(np.concatenate([y_all, y_pred]))\n",
        "cm = confusion_matrix(y_all, y_pred, labels=labels)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm,\n",
        "    index=[f\"true_{c}\" for c in labels],\n",
        "    columns=[f\"pred_{c}\" for c in labels],\n",
        ")\n",
        "display(cm_df)\n",
        "\n",
        "# salvar\n",
        "os.makedirs(\"/content/reports\", exist_ok=True)\n",
        "cm_path = \"/content/reports/confusion_matrix_full.csv\"\n",
        "cm_df.to_csv(cm_path, index=True)\n",
        "print(\"Matriz salva em:\", cm_path)\n",
        "\n",
        "# atualiza metadata para refletir o out_dim real do checkpoint\n",
        "if meta.get(\"n_classes\", None) != int(out_dim_ckpt):\n",
        "    meta[\"n_classes\"] = int(out_dim_ckpt)\n",
        "    with open(\"/content/models/final_metadata.json\", \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "    print(f\"Metadata atualizado: n_classes = {int(out_dim_ckpt)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NByUvWsFFEa"
      },
      "source": [
        "Conclusão.\n",
        "Após busca em grade com validação cruzada 5-fold, o modelo vencedor foi um MLP com camada oculta [256] e lr=1e-3. O desempenho médio em CV foi F1-macro = 0,6759 ± 0,0197 (métricas por fold no notebook). Geramos predições out-of-fold e a matriz de confusão correspondente. Para empacotamento, o modelo foi treinado com todos os dados, e os artefatos foram salvos: pesos (final_mlp.pth), scaler (final_scaler.pkl) e metadados (final_metadata.json). A rotina de recarga foi validada prevendo todo o dataset e exportando a matriz final em /content/reports/confusion_matrix_full.csv."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}